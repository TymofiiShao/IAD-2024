{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SREcKwjF-GZn"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model='ai-forever/mGPT')\n",
        "\n",
        "generated_texts = generator(\n",
        "    \"Необхідно створити презентацію, яка коротко демонструє переваги KAN над класичними нейромережами.\",\n",
        "    max_length=125\n",
        ")\n",
        "\n",
        "# Iterate through the generated sequences, replace newline characters, and print\n",
        "for i, generated_text in enumerate(generated_texts):\n",
        "    formatted_text = generated_text['generated_text'].replace(\"\\n\", \" \")\n",
        "    print(f\"\\033[1;34m[{i + 1}] generated_text:\\n\\033[0;30m'{formatted_text}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHYYmOSa-fxs",
        "outputId": "3c17715d-d70f-44eb-809d-aff86bb24117"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;34m[1] generated_text:\n",
            "\u001b[0;30m'Необхідно створити презентацію, яка коротко демонструє переваги KAN над класичними нейромережами. Під час презентації необхідно використовувати інформаційні технології, що дозволяють відображати інформацію відразу на декількох рівнях. Під час презентації необхід'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"spursyy/mT5_multilingual_XLSum_rust\")\n",
        "\n",
        "text_to_summarize = \"\"\"\n",
        "Tesla відкликає близько 700 тис. електромобілів\n",
        "\n",
        "Tesla відкликає близько 700 тис. електромобілів Model 3 і Model Y, а також електропікапів Cybertruck. Про це пише MarketWatch.\n",
        "\n",
        "Компанія повідомила, що виявила несправність системи контролю тиску в шинах, яка, якщо її не усунути, підвищує ризик аварії. Водночас цю проблему можна вирішити за допомогою віддаленого оновлення програмного забезпечення.\n",
        "\n",
        "Контрольна лампа системи тиску в шинах у зачеплених відкликанням транспортних засобах може не спалахувати і не попереджати водія про низький тиск. Зниження тиску в шинах є досить поширеною проблемою в умовах холодної погоди, зазначає MarketWatch.\n",
        "\n",
        "\"\"\"\n",
        "summarized_text = summarizer(text_to_summarize, max_length=250, min_length=50)\n",
        "print(\"Summarized Text (Ukrainian):\", summarized_text[0]['summary_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGMrGo5_Mvz",
        "outputId": "a8907dc6-d67b-4b32-a267-04656c66eb02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Your max_length is set to 250, but your input_length is only 201. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized Text (Ukrainian): Компанія Tesla відкликає сотні тисяч електромобілів і електропікапів через несправність системи контролю тиску в шинах, повідомляють британські ЗМІ. Причиною цього стала проблема безпеки.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "\n",
        "question = \"Скільки коштує великий лате?\"\n",
        "context = \"\"\"\n",
        "Доброго дня, друзі! У нас у кафе сьогодні просто фантастична пропозиція, яку неможливо пропустити! Маленький лате всього за 35 гривень! Так, ви правильно почули – якісна ароматна кава зі свіжим молоком і ніжною пінкою за таку доступну ціну!\n",
        "\n",
        "Уявіть собі, як ця тепла чашка кави зігріє ваші руки і подарує трохи спокою в цей активний день. Наш лате – це ідеальний баланс між міцністю еспресо і ніжністю молока. Ми готуємо його з найкращих зерен, щоб кожен ковток приносив задоволення.\n",
        "\n",
        "Чому варто спробувати саме сьогодні? Така ціна діє лише обмежений час! Крім того, у нас можна замовити лате на рослинному молоці, якщо ви віддаєте перевагу альтернативам.\n",
        "\n",
        "Чудова кава – це найкращий спосіб зробити свій день трішки яскравішим. Забігайте, ми вже готові зробити ваш лате і подарувати вам трішки щастя у чашці! Наша адреса зовсім поруч, не проходьте повз!\n",
        "\"\"\"\n",
        "\n",
        "answer = qa_model(question = question, context = context)\n",
        "print(\"Відповідь:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8kX47Xv_gSH",
        "outputId": "7e43e318-f09a-430a-fe32-0dd69f792e52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Відповідь: {'score': 3.072613594667928e-07, 'start': 124, 'end': 136, 'answer': ' 35 гривень!'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline('fill-mask', model='xlm-roberta-base', top_k=5)\n",
        "\n",
        "whos = unmasker(\"Лекційні матеріали та <mask> практичних занять можна знайти тут\")\n",
        "for who in whos:\n",
        "    print(who['token_str'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oash11FQ_m-H",
        "outputId": "eb8c7e9f-1f3a-46c7-c171-a9ced3428f0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "плани\n",
            "програми\n",
            "план\n",
            "графік\n",
            "розробки\n"
          ]
        }
      ]
    }
  ]
}